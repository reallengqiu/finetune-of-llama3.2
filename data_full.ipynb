{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/multillama/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image_path', 'caption'],\n",
      "    num_rows: 2585\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Features, Value, Sequence,DatasetDict,load_dataset\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 定义数据集的特征\n",
    "features = Features({\n",
    "    \"image_path\": Value(\"string\"),\n",
    "    \"caption\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "# 读取JSON文件并构建数据集\n",
    "def load_custom_dataset(json_file_path, image_folder_path):\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    dataset_data = {\n",
    "        \"image_path\": [],\n",
    "        \"caption\": [],\n",
    "    }\n",
    "    for annotation in data[\"annotations\"]:\n",
    "        image_path = os.path.join(image_folder_path, annotation[\"filename\"])\n",
    "        \n",
    "        dataset_data[\"image_path\"].append(image_path)\n",
    "        dataset_data[\"caption\"].append(annotation[\"caption\"])\n",
    "    \n",
    "    # 创建数据集\n",
    "    dataset = Dataset.from_dict(dataset_data, features=features)\n",
    "    return dataset\n",
    "\n",
    "# 调用\n",
    "json_file_path = \"./data/RSICap/captions.json\"  # JSON文件路径\n",
    "image_folder_path = \"./data/RSICap/images/\"  # 图片文件夹路径\n",
    "dataset = load_custom_dataset(json_file_path, image_folder_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 2068\n",
      "Validation dataset size: 258\n",
      "Test dataset size: 259\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image_path', 'caption'],\n",
      "        num_rows: 2068\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image_path', 'caption'],\n",
      "        num_rows: 258\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image_path', 'caption'],\n",
      "        num_rows: 259\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 划分数据集，这里以80%的数据作为训练集\n",
    "dataset_split = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# 进一步将验证集划分为验证集和测试集，这里以验证集和测试集各占原数据集10%为例\n",
    "test_valid_split = dataset_split['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "# 最终得到训练集、验证集和测试集\n",
    "train_dataset = dataset_split['train']\n",
    "valid_dataset = test_valid_split['train']\n",
    "test_dataset = test_valid_split['test']\n",
    "\n",
    "# 创建DatasetDict对象\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': valid_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "\n",
    "# 打印各数据集的大小\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义保存JSON文件的路径\n",
    "train_path = \"/home/hhf/workspace/llama/data/RSICap/train.json\"\n",
    "validation_path = \"/home/hhf/workspace/llama/data/RSICap/validation.json\"\n",
    "test_path = \"/home/hhf/workspace/llama/data/RSICap/test.json\"\n",
    "\n",
    "# 将DatasetDict中的每个部分保存为JSON文件\n",
    "def save_dataset_to_json(dataset_dict, train_path, validation_path, test_path):\n",
    "    # 保存训练集\n",
    "    with open(train_path, 'w', encoding='utf-8') as f:\n",
    "        for item in dataset_dict['train']:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # 保存验证集\n",
    "    with open(validation_path, 'w', encoding='utf-8') as f:\n",
    "        for item in dataset_dict['validation']:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # 保存测试集\n",
    "    with open(test_path, 'w', encoding='utf-8') as f:\n",
    "        for item in dataset_dict['test']:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "# 调用函数保存数据集\n",
    "save_dataset_to_json(dataset_dict, train_path, validation_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 2068 examples [00:00, 279800.67 examples/s]\n",
      "Generating validation split: 258 examples [00:00, 50578.66 examples/s]\n",
      "Generating test split: 259 examples [00:00, 52632.01 examples/s]\n",
      "Map: 100%|██████████| 2068/2068 [03:33<00:00,  9.67 examples/s] \n",
      "Map: 100%|██████████| 258/258 [00:18<00:00, 14.17 examples/s] \n",
      "Map: 100%|██████████| 259/259 [00:17<00:00, 14.43 examples/s] \n",
      "Saving the dataset (2/2 shards): 100%|██████████| 2068/2068 [00:01<00:00, 1358.85 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 258/258 [00:00<00:00, 1954.10 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 259/259 [00:00<00:00, 1977.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_path': './data/RSICap/images/P2141_0007.png', 'caption': 'This is an aerial image that depicts an area near a football field. Specifically, the football field is located in the upper left corner of the image. Surrounding the football field, there is a grey-colored running track. In the upper right corner of the image, there is a patch of forest. Moving towards the bottom right corner of the image, there is an open area with three cars on it. In the upper left area of the open area, there is another patch of forest. And in the bottom left corner of the open area, there is a swimming pool.', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x701E39327DD0>}\n",
      "{'image_path': './data/RSICap/images/P2141_0007.png', 'caption': 'This is an aerial image that depicts an area near a football field. Specifically, the football field is located in the upper left corner of the image. Surrounding the football field, there is a grey-colored running track. In the upper right corner of the image, there is a patch of forest. Moving towards the bottom right corner of the image, there is an open area with three cars on it. In the upper left area of the open area, there is another patch of forest. And in the bottom left corner of the open area, there is a swimming pool.', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x701E39326B10>}\n",
      "{'image_path': './data/RSICap/images/P0896_0015.png', 'caption': 'This is an aerial image showing water bodies. In the top portion of the image, there are seven ships and three partially visible buildings. On the right side of the image, there is a partially visible road.', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x701E393263D0>}\n",
      "{'image_path': './data/RSICap/images/P2257_0005.png', 'caption': 'This is an aerial image that shows a playground on the left side of the image with a soccer field located in the center of the playground. There is a grass area located below the playground. A brown bare land area surrounded by trees is located on the right side of the image.', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=512x512 at 0x701E3930D690>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义一个函数，用于加载图像并转换为张量\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "# 加载数据集\n",
    "dataset_path = \"/home/hhf/workspace/llama/data/RSICap\"\n",
    "train_dataset = load_dataset('json', data_files={'train': f'{dataset_path}/train.json'})['train']\n",
    "validation_dataset = load_dataset('json', data_files={'validation': f'{dataset_path}/validation.json'})['validation']\n",
    "test_dataset = load_dataset('json', data_files={'test': f'{dataset_path}/test.json'})['test']\n",
    "\n",
    "# 定义一个映射函数，用于加载图像和文本\n",
    "def preprocess_example(example):\n",
    "    example['image'] = load_image(example['image_path'])\n",
    "    return example\n",
    "\n",
    "# 应用映射函数\n",
    "train_dataset = train_dataset.map(preprocess_example)\n",
    "validation_dataset = validation_dataset.map(preprocess_example)\n",
    "test_dataset = test_dataset.map(preprocess_example)\n",
    "\n",
    "# 构建 DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "#储存处理后的数据至本地\n",
    "dataset_dict.save_to_disk('./data/dataset_full/')\n",
    "\n",
    "# 打印第一个样本\n",
    "print(dataset_dict['train'][0])\n",
    "\n",
    "#重新加载\n",
    "from datasets import load_from_disk\n",
    "train_dataset_new = load_from_disk('./data/dataset_full/train')\n",
    "validation_dataset_new = load_from_disk('./data/dataset_full/validation')\n",
    "test_dataset_new = load_from_disk('./data/dataset_full/test')\n",
    "\n",
    "print(train_dataset_new[0])\n",
    "print(validation_dataset_new[0])\n",
    "print(test_dataset_new[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multillama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
